# LLM训练指南
## LLM做了什么？/LLM的工作原理
在我们与chatgpt进行对话的过程中，只需要输入你的问题或者请求，LLM会根据其所学习的数据和模式来生成回应。

### 输入->模型->输出
我们可以把模型理解为一个函数，接收输入，处理后输出。
这个函数中有着大量的参数。

### LLM其实是在做文字接龙
*（文字接龙是一种可以不断重复执行的操作。）*
>例如，如果您在 LLM中输入：“How are”，它将计算下一个词的可能性。
>它可以将 60% 的概率分配给“you”，20% 的概率“things”，依此类推。
>它会选择概率最大的字。接着，它会将这个字加至原来输入的末尾，即“How are you”，作为新的输入继续文字接龙。
模型/这个函数其实是在计算下一个词的可能性并输出。

### 本质：一种文本的有损压缩形式
LLM从大量的文本数据提取出其中规律与关联（“有损压缩”），这些模式将以概率的形式体现在模型中：模型学习特定的字后跟另一个字的概率有多高，以此类推。
实现过程大致是：
- 生成随机值的参数——生成包含随机值和参数的张量（多维矩阵）
- 通过学习文本数据修改参数——向这些张量输入大量的文本数据（达到TB级别！），使模型能够学习所有数据之间的关系并识别它们之间的模式，这些模式以概率的形式存储在我们随机初始化的张量中
如果用一个非常高级的定义来描述LLMs，那就是“将一种语言（如英语）的概率分布压缩到一系列矩阵中”。

### 昂贵？
上面讨论的随机初始化在很大程度上不适用于我们，因为它非常昂贵（我们谈论的是大型模型的数百万美元）。
接下来的内容将以“对模型进行微调”为重点——也就是说，采用一个预先训练的模型并向其提供少量数据（通常为几 MB），以使其行为与您心目中的任何下游任务保持一致。
例如，如果需要编码助手模型，则可以根据编码示例对模型进行微调，依此类推。


## 架构，transformer架构（待施工）

## 如何训练一个LLM？/训练方法
基本上有三种训练LLMs方法：预训练、微调和LoRA/Q-LoRA
### 预训练
### 微调
### LoRA/Q-LoRA

## 微调
